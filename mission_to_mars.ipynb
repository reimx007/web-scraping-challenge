{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "import time\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit visitcostarica.herokuapp.com\n",
    "url1 = \"https://mars.nasa.gov/news/\"\n",
    "url2 = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "url3 = \"https://twitter.com/marswxreport?lang=en\"\n",
    "url4 = \"https://space-facts.com/mars/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the news title from \"https://mars.nasa.gov/news/\"\n",
    "response1 = requests.get(url1)\n",
    "time.sleep(1)\n",
    "# Scrape page into Soup\n",
    "html1 = response1.text\n",
    "soup1 = bs(html1, \"html.parser\")\n",
    "news_title = soup1.find_all('div', class_=\"content_title\")[0].text\n",
    "\n",
    "# ===============================================================================\n",
    "# CAN'T GET THE NEWS PARAGRAPH\n",
    "# ===============================================================================\n",
    "# results = soup1.find_all('div', class_=\"image_and_description_container\")\n",
    "# news_p = soup1.find_all('div', class_=\"article_teaser_body\").text\n",
    "\n",
    "print(news_title)\n",
    "# print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mars images from \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "executable_path = {'executable_path': '/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "browser.visit(url2)\n",
    "time.sleep(1)\n",
    "# Scrape page into Soup\n",
    "html2 = browser.html\n",
    "soup2 = bs(html2, \"html.parser\")\n",
    "partial_url = soup2.find_all('img')[3][\"src\"]\n",
    "# featured_image_url = soup2.find('div', id='?????')\n",
    "# print(f\" {categories}\")\n",
    "image_url = \"https://www.jpl.nasa.gov\" + partial_url\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d2697746f4c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhtml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msoup3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0marticle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# tweet = article.find('span', {'class': 'css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# mars_weather = soup3.find('div', id='?????')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get the mars weather from \"https://twitter.com/marswxreport?lang=en\"\n",
    "response3 = requests.get(url3)\n",
    "time.sleep(1)\n",
    "# Scrape page into Soup\n",
    "html3 = response3.text\n",
    "soup3 = bs(html3, \"html.parser\")\n",
    "article = soup3.find_all('article')[0]\n",
    "# tweet = article.find('span', {'class': 'css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'})\n",
    "# mars_weather = soup3.find('div', id='?????')\n",
    "print(article)\n",
    "# print(tweet)\n",
    "\n",
    "# ===============================================================================\n",
    "# CAN'T GET THE TWEET\n",
    "# ==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url4)\n",
    "df = tables[0]\n",
    "df.columns = ['Attribute', 'Value']\n",
    "df.set_index('Attribute', inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = df.to_html()\n",
    "html_table.replace('\\n', '')\n",
    "df.to_html('mars_facts.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of hemisphere image URLs\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all aquired info\n",
    "mars_data = {\n",
    "        \"news_title\": news_title,\n",
    "#         \"news_p\" : news_p,\n",
    "        \"image_url\": image_url,\n",
    "#         \"tweet\": tweet,\n",
    "        \"html_table\": html_table,\n",
    "        \"hemisphere_image_urls\": hemisphere_image_urls\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
